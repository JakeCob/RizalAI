{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTKeywordTableIndex, SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "## by default, LlamaIndex uses text-davinci-003 to synthesise response\n",
    "# and text-davinci-002 for embedding, we can change to\n",
    "# gpt-3.5-turbo for Chat model\n",
    "index = GPTListIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is net operating income?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))\n",
    "\n",
    "## Check the logs to see the different between th\n",
    "## if you wish to not build the index during the index construction\n",
    "# then need to add retriever_mode=embedding to query engine\n",
    "# query with embed_model specified\n",
    "query_engine = new_index.as_query_engine(\n",
    "    retriever_mode=\"embedding\", \n",
    "    verbose=True\n",
    ")\n",
    "response = query_engine.query(\"What is net operating income?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rizal-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
